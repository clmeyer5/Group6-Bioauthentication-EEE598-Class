{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU-_oTuBVVSk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import os\n",
        "import joblib\n",
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from collections import namedtuple\n",
        "from typing import List\n",
        "import numpy as np\n",
        "import wfdb\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.fft import fft, fftfreq\n",
        "from scipy.interpolate import interp1d\n",
        "from datetime import datetime\n",
        "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
        "import copy\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from mlp import *\n",
        "from data import *\n",
        "from ae import *\n",
        "from utils import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5MxyvNaVrvi",
        "outputId": "a59310c7-4695-4c75-b480-e7fd6a186eb8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using dataset from Google Drive: /content/drive/MyDrive/gesture-recognition-and-biometrics-electromyogram-grabmyo-1.1.0.zip\n",
            "\n",
            "Extracting files...\n",
            "Dataset extracted to: grabmyo_data\n",
            "âœ“ Extraction complete! Marker file created.\n"
          ]
        }
      ],
      "source": [
        "dataset_path = download_grabmyo_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "DATA_ROOT = 'grabmyo_data'\n",
        "GESTURE = 1\n",
        "INCLUDE_CHANNELS = [9,10,11,12,13,14,15,16,18,19,20,21,22,23]\n",
        "# INCLUDE_CHANNELS = [9,10,11,15]\n",
        "FS = 2000\n",
        "RANDOM_SEED = 42\n",
        "\n",
        "set_random_seeds(RANDOM_SEED)\n",
        "# Load raw data\n",
        "metadata, signals, channel_names = load_emg_data(\n",
        "    data_root=DATA_ROOT,\n",
        "    gesture=GESTURE,\n",
        "    include_indices=INCLUDE_CHANNELS\n",
        ")\n",
        "\n",
        "print(f\"\\nSignal shape: {signals.shape}\")\n",
        "print(f\"Number of trials: {len(metadata)}\")\n",
        "print(f\"Number of subjects: {metadata['subject'].nunique()}\")\n",
        "print(f\"Channels: {len(channel_names)}\")\n",
        "\n",
        "\n",
        "# Load raw data\n",
        "metadata, signals, channel_names = load_emg_data(\n",
        "    data_root=DATA_ROOT,\n",
        "    gesture=GESTURE,\n",
        "    include_indices=INCLUDE_CHANNELS\n",
        ")\n",
        "\n",
        "print(f\"\\nSignal shape: {signals.shape}\")\n",
        "print(f\"Number of trials: {len(metadata)}\")\n",
        "print(f\"Number of subjects: {metadata['subject'].nunique()}\")\n",
        "print(f\"Channels: {len(channel_names)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        },
        "id": "Xz6Pr6PPZkSd",
        "outputId": "af8ecdbb-4978-4e82-85d8-d182f093e486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Loading gestures: [1, 11, 12, 13, 16]...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3264920797.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading gestures: {GESTURES}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mGESTURES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_emg_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grabmyo_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgesture\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mall_signals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mall_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-13281648.py\u001b[0m in \u001b[0;36mload_emg_data\u001b[0;34m(data_root, gesture, include_indices)\u001b[0m\n\u001b[1;32m     36\u001b[0m                         \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                     \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwfdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdrecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                     \u001b[0memg_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp_signal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdrecord\u001b[0;34m(record_name, sampfrom, sampto, channels, physical, pn_dir, m2s, smooth_frames, ignore_skew, return_res, force_channels, channel_names, warn_empty)\u001b[0m\n\u001b[1;32m   2049\u001b[0m             )\n\u001b[1;32m   2050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2051\u001b[0;31m     \u001b[0mrecord\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpn_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpn_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrd_segments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2053\u001b[0m     \u001b[0;31m# Set defaults for sampto and channels input variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wfdb/io/record.py\u001b[0m in \u001b[0;36mrdheader\u001b[0;34m(record_name, pn_dir, rd_segments)\u001b[0m\n\u001b[1;32m   1875\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader_lines\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m             \u001b[0;31m# Read the fields from the signal lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1877\u001b[0;31m             \u001b[0msignal_fields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_header\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_signal_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1878\u001b[0m             \u001b[0;31m# Set the object's signal fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msignal_fields\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/wfdb/io/_header.py\u001b[0m in \u001b[0;36m_parse_signal_lines\u001b[0;34m(signal_lines)\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0;31m# that different channels can be present or missing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msignal_fields\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m                 signal_fields[field][ch] = SIGNAL_SPECS.loc[\n\u001b[0m\u001b[1;32m   1121\u001b[0m                     \u001b[0mfield\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read_default\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m                 ]\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_takeable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4230\u001b[0m             \u001b[0;31m#  results if our categories are integers that dont match our codes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4231\u001b[0m             \u001b[0;31m# IntervalIndex: IntervalTree has no get_loc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4232\u001b[0;31m             \u001b[0mrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4233\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3782\u001b[0m     \u001b[0;31m# Indexing Methods\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3784\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3785\u001b[0m         \"\"\"\n\u001b[1;32m   3786\u001b[0m         \u001b[0mGet\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mboolean\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrequested\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "GESTURES = [1, 11, 12, 13, 16]\n",
        "all_signals = []\n",
        "all_metadata = []\n",
        "print(f\"Loading gestures: {GESTURES}...\")\n",
        "for g in GESTURES:\n",
        "    meta, sig, _ = load_emg_data(data_root='grabmyo_data', gesture=g)\n",
        "    all_signals.append(sig)\n",
        "all_metadata.append(meta)\n",
        "signals_raw = np.concatenate(all_signals, axis=0)\n",
        "metadata_combined = pd.concat(all_metadata, ignore_index=True)\n",
        "print(f\"Total trials loaded: {signals_raw.shape[0]}\")\n",
        "signals_clean = clean_all_trials(signals_raw)\n",
        "\n",
        "X_train, X_test = DataPreprocessor.split_data(ts_data=signals_clean)\n",
        "X_train_scaled, X_test_scaled, scaler = DataPreprocessor.scale_ts_features(X_train_raw=X_train, X_test_raw=X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1Gv1Et-Zr43",
        "outputId": "a85bf56b-9892-4f7e-ef48-376f95e92fc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Samples: 85965\n",
            "Validation Samples: 15171\n",
            "Starting training on cuda...\n",
            "Epoch [1/100] Train Loss: 1.07713 | Val Loss: 0.99289\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [2/100] Train Loss: 0.99645 | Val Loss: 0.98044\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [3/100] Train Loss: 0.97528 | Val Loss: 0.95712\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [4/100] Train Loss: 0.94003 | Val Loss: 0.91661\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [5/100] Train Loss: 0.88912 | Val Loss: 0.86588\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [6/100] Train Loss: 0.82367 | Val Loss: 0.80896\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [7/100] Train Loss: 0.76572 | Val Loss: 0.75902\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [8/100] Train Loss: 0.71603 | Val Loss: 0.71283\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [9/100] Train Loss: 0.67045 | Val Loss: 0.68319\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [10/100] Train Loss: 0.63479 | Val Loss: 0.65768\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [11/100] Train Loss: 0.60490 | Val Loss: 0.63375\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [12/100] Train Loss: 0.57835 | Val Loss: 0.61661\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [13/100] Train Loss: 0.55567 | Val Loss: 0.60121\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [14/100] Train Loss: 0.53394 | Val Loss: 0.58819\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [15/100] Train Loss: 0.51774 | Val Loss: 0.57765\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [16/100] Train Loss: 0.50000 | Val Loss: 0.56138\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [17/100] Train Loss: 0.48320 | Val Loss: 0.55825\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [18/100] Train Loss: 0.46949 | Val Loss: 0.54869\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [19/100] Train Loss: 0.45652 | Val Loss: 0.53796\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [20/100] Train Loss: 0.44344 | Val Loss: 0.53170\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [21/100] Train Loss: 0.43442 | Val Loss: 0.52815\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [22/100] Train Loss: 0.42410 | Val Loss: 0.52071\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [23/100] Train Loss: 0.41515 | Val Loss: 0.51559\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [24/100] Train Loss: 0.40686 | Val Loss: 0.51292\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [25/100] Train Loss: 0.39832 | Val Loss: 0.50571\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [26/100] Train Loss: 0.39033 | Val Loss: 0.50388\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [27/100] Train Loss: 0.38236 | Val Loss: 0.49853\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [28/100] Train Loss: 0.37629 | Val Loss: 0.49557\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [29/100] Train Loss: 0.37095 | Val Loss: 0.49220\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [30/100] Train Loss: 0.36429 | Val Loss: 0.48922\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [31/100] Train Loss: 0.35920 | Val Loss: 0.48505\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [32/100] Train Loss: 0.35327 | Val Loss: 0.48480\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [33/100] Train Loss: 0.35008 | Val Loss: 0.48201\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [34/100] Train Loss: 0.34531 | Val Loss: 0.48058\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [35/100] Train Loss: 0.33976 | Val Loss: 0.47525\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [36/100] Train Loss: 0.33433 | Val Loss: 0.47254\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [37/100] Train Loss: 0.32906 | Val Loss: 0.47139\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [38/100] Train Loss: 0.32553 | Val Loss: 0.47031\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [39/100] Train Loss: 0.32184 | Val Loss: 0.46786\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [40/100] Train Loss: 0.31761 | Val Loss: 0.46757\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [41/100] Train Loss: 0.31501 | Val Loss: 0.46394\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [42/100] Train Loss: 0.31089 | Val Loss: 0.46415\n",
            "Epoch [43/100] Train Loss: 0.30912 | Val Loss: 0.46756\n",
            "Epoch [44/100] Train Loss: 0.30546 | Val Loss: 0.46215\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [45/100] Train Loss: 0.30211 | Val Loss: 0.46282\n",
            "Epoch [46/100] Train Loss: 0.30100 | Val Loss: 0.46245\n",
            "Epoch [47/100] Train Loss: 0.29859 | Val Loss: 0.45735\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [48/100] Train Loss: 0.29702 | Val Loss: 0.45575\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [49/100] Train Loss: 0.28973 | Val Loss: 0.45258\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [50/100] Train Loss: 0.28662 | Val Loss: 0.45272\n",
            "Epoch [51/100] Train Loss: 0.28470 | Val Loss: 0.45183\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [52/100] Train Loss: 0.28373 | Val Loss: 0.45006\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [53/100] Train Loss: 0.27918 | Val Loss: 0.44873\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [54/100] Train Loss: 0.27723 | Val Loss: 0.44755\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [55/100] Train Loss: 0.27590 | Val Loss: 0.44868\n",
            "Epoch [56/100] Train Loss: 0.27546 | Val Loss: 0.44726\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [57/100] Train Loss: 0.27340 | Val Loss: 0.44746\n",
            "Epoch [58/100] Train Loss: 0.27163 | Val Loss: 0.44530\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [59/100] Train Loss: 0.26743 | Val Loss: 0.44514\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [60/100] Train Loss: 0.26660 | Val Loss: 0.44276\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [61/100] Train Loss: 0.26427 | Val Loss: 0.44334\n",
            "Epoch [62/100] Train Loss: 0.26241 | Val Loss: 0.44213\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [63/100] Train Loss: 0.26008 | Val Loss: 0.44159\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [64/100] Train Loss: 0.25941 | Val Loss: 0.44053\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [65/100] Train Loss: 0.25665 | Val Loss: 0.43999\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [66/100] Train Loss: 0.25484 | Val Loss: 0.43871\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [67/100] Train Loss: 0.25260 | Val Loss: 0.43918\n",
            "Epoch [68/100] Train Loss: 0.25134 | Val Loss: 0.44081\n",
            "Epoch [69/100] Train Loss: 0.25024 | Val Loss: 0.43728\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [70/100] Train Loss: 0.24898 | Val Loss: 0.43610\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [71/100] Train Loss: 0.24827 | Val Loss: 0.43834\n",
            "Epoch [72/100] Train Loss: 0.24621 | Val Loss: 0.43435\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [73/100] Train Loss: 0.24358 | Val Loss: 0.43947\n",
            "Epoch [74/100] Train Loss: 0.24245 | Val Loss: 0.43321\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [75/100] Train Loss: 0.24229 | Val Loss: 0.43420\n",
            "Epoch [76/100] Train Loss: 0.23990 | Val Loss: 0.43239\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [77/100] Train Loss: 0.24152 | Val Loss: 0.43783\n",
            "Epoch [78/100] Train Loss: 0.23749 | Val Loss: 0.43251\n",
            "Epoch [79/100] Train Loss: 0.23660 | Val Loss: 0.43260\n",
            "Epoch [80/100] Train Loss: 0.23637 | Val Loss: 0.43145\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [81/100] Train Loss: 0.23382 | Val Loss: 0.43180\n",
            "Epoch [82/100] Train Loss: 0.23190 | Val Loss: 0.42985\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [83/100] Train Loss: 0.23184 | Val Loss: 0.43040\n",
            "Epoch [84/100] Train Loss: 0.22971 | Val Loss: 0.42927\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [85/100] Train Loss: 0.22860 | Val Loss: 0.42813\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [86/100] Train Loss: 0.22722 | Val Loss: 0.43043\n",
            "Epoch [87/100] Train Loss: 0.22782 | Val Loss: 0.42974\n",
            "Epoch [88/100] Train Loss: 0.22602 | Val Loss: 0.42953\n",
            "Epoch [89/100] Train Loss: 0.22456 | Val Loss: 0.42747\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [90/100] Train Loss: 0.22432 | Val Loss: 0.42774\n",
            "Epoch [91/100] Train Loss: 0.22419 | Val Loss: 0.42911\n",
            "Epoch [92/100] Train Loss: 0.22481 | Val Loss: 0.42684\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [93/100] Train Loss: 0.22160 | Val Loss: 0.42954\n",
            "Epoch [94/100] Train Loss: 0.21940 | Val Loss: 0.42566\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [95/100] Train Loss: 0.21996 | Val Loss: 0.42606\n",
            "Epoch [96/100] Train Loss: 0.21712 | Val Loss: 0.42447\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [97/100] Train Loss: 0.21647 | Val Loss: 0.42464\n",
            "Epoch [98/100] Train Loss: 0.21614 | Val Loss: 0.42430\n",
            "Model saved to emg_clean_split_best.pth\n",
            "Epoch [99/100] Train Loss: 0.21487 | Val Loss: 0.42590\n",
            "Epoch [100/100] Train Loss: 0.21411 | Val Loss: 0.42504\n",
            "Loaded best model weights.\n"
          ]
        }
      ],
      "source": [
        "train_tensor = torch.from_numpy(X_train_scaled).float().to(device)\n",
        "test_tensor = torch.from_numpy(X_test_scaled).float().to(device)\n",
        "\n",
        "# 1. Create the Full Training Dataset\n",
        "full_train_dataset = TensorDataset(train_tensor)\n",
        "\n",
        "# 2. Calculate Split Sizes (e.g., 85% Train, 15% Validation)\n",
        "train_size = int(0.85 * len(full_train_dataset))\n",
        "val_size = len(full_train_dataset) - train_size\n",
        "\n",
        "# 3. Randomly Split\n",
        "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
        "\n",
        "print(f\"Training Samples: {len(train_dataset)}\")\n",
        "print(f\"Validation Samples: {len(val_dataset)}\")\n",
        "\n",
        "# 4. Initialize Model\n",
        "model = AE(\n",
        "    input_len=train_tensor.shape[2],\n",
        "    input_channels=1,\n",
        "    latent_dim=20,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "X_train_split = torch.stack([train_dataset[i][0] for i in range(len(train_dataset))])\n",
        "X_val_split = torch.stack([val_dataset[i][0] for i in range(len(val_dataset))])\n",
        "\n",
        "model.train_ae(\n",
        "    train_data=X_train_split,\n",
        "    val_data=X_val_split,      \n",
        "    model_name=\"emg_clean_split\",\n",
        "    LR=0.001,\n",
        "    EPOCHS=100,\n",
        "    batch_size=650,\n",
        "    patience=15\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "2nHT0xFPY_aw",
        "outputId": "faedcc4c-054c-4094-cb10-02d00a918125"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_tensor' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3192708557.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Grab 28 samples (which equals 1 full subject if data is ordered)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mnum_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0msample_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_channels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0mreconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_tensor' is not defined"
          ]
        }
      ],
      "source": [
        "# Test AE\n",
        "\n",
        "with torch.no_grad():\n",
        "    num_channels = 28\n",
        "    sample_input = test_tensor[:num_channels]\n",
        "\n",
        "    reconstruction = model(sample_input)\n",
        "\n",
        "    mse = torch.nn.functional.mse_loss(reconstruction, sample_input)\n",
        "    print(f\"Test Set MSE Loss: {mse.item():.5f}\")\n",
        "\n",
        "    # Visualize\n",
        "    rec_real = inverse_transform_output(reconstruction, scaler, original_num_channels=num_channels)\n",
        "    print(\"Reconstructed Shape (Original Units):\", rec_real.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "jtEJFWq7sizv",
        "outputId": "c4438e39-4d91-4fb0-9175-419004de031b"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'scaler' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3986257368.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ts_scaler.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'scaler' is not defined"
          ]
        }
      ],
      "source": [
        "# Save Scalers for later use\n",
        "joblib.dump(scaler, 'ts_scaler.pkl')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
